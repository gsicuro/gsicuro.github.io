<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gabriele Sicuro</title>
    <link>https://gsicuro.github.io/</link>
      <atom:link href="https://gsicuro.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Gabriele Sicuro</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://gsicuro.github.io/media/icon_hu7f2426718c726843532e5bf53de698ef_1775364_512x512_fill_lanczos_center_3.png</url>
      <title>Gabriele Sicuro</title>
      <link>https://gsicuro.github.io/</link>
    </image>
    
    <item>
      <title>The Cross-Disciplinary Approaches to Non-Equilibrium Systems Centre</title>
      <link>https://gsicuro.github.io/education/canes/</link>
      <pubDate>Wed, 07 Apr 2021 10:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/education/canes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spazi vettoriali</title>
      <link>https://gsicuro.github.io/lectures/im2/ch1/sec1/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/lectures/im2/ch1/sec1/</guid>
      <description>&lt;h3 id=&#34;vettori-applicati-e-vettori-geometrici&#34;&gt;Vettori applicati e vettori geometrici&lt;/h3&gt;
&lt;p&gt;Per introdurre il concetto di &lt;em&gt;spazio vettoriale&lt;/em&gt; iniziamo da un
contesto più concreto e forse più semplice. Consideriamo due punti $A$ e
$B$ nello spazio &lt;em&gt;ordinario&lt;/em&gt;. Un &lt;em&gt;vettore applicato
${\boldsymbol v}=\overrightarrow{AB}$ in $A$ con punto finale $B$&lt;/em&gt; può
essere immaginato come una freccia che collega $A$ e $B$,&lt;/p&gt;
&lt;img src=&#34;https://gsicuro.github.io/images/im2/main-0.jpg&#34; alt=&#34;vettore&#34; style=&#34;width:20%;&#34;/&gt; 
&lt;p&gt;Un vettore applicato è caratterizzato dal suo punto di applicazione,
$A$, da una direzione, un verso e una lunghezza. Se $A=B$, allora il
corrispondente vettore è detto &lt;em&gt;nullo&lt;/em&gt; e viene indicato con $\mathbf 0$:
la sua lunghezza è zero e la sua direzione e il suo verso non sono
definiti. Due vettori ${\boldsymbol v}=\overrightarrow{AB}$ e
${\boldsymbol u}=\overrightarrow{CD}$ sono &lt;em&gt;equipollenti&lt;/em&gt; se hanno
stessa direzione, stessa lunghezza e stesso verso. L&amp;rsquo;equipollenza è una
relazione di equivalenza e un &lt;em&gt;vettore geometrico&lt;/em&gt; corrisponde ad una
classe di equivalenza secondo equipollenza. Uno specifico vettore
applicato è perciò un &lt;em&gt;rappresentante&lt;/em&gt; di questa classe di equivalenza,
mentre tutti i vettori con stessa direzione, stessa lunghezza e stesso
verso corrispondono allo stesso oggetto di tipo &amp;ldquo;vettore geometrico&amp;rdquo;.&lt;/p&gt;
&lt;h4 id=&#34;operazioni-tra-vettori-geometrici&#34;&gt;Operazioni tra vettori geometrici&lt;/h4&gt;
&lt;p&gt;I vettori geometrici sono oggetti molto diversi dai numeri usuali, ma è
ugualmente possibile introdurre una serie di operazioni tra di essi.&lt;/p&gt;
&lt;p&gt;Dati due vettori geometrici ${\boldsymbol v}$ e ${\boldsymbol u}$, la
loro &lt;em&gt;somma&lt;/em&gt; ${\boldsymbol u}+{\boldsymbol v}$ può essere definita
concatenando due loro rappresentanti. Per esempio, scelto un punto $A$,
si applica prima ${\boldsymbol v}$ ad $A$ si ottiene il vettore
$\overrightarrow{AB}$ con coda in un punto $B$, e, consecutivamente,
applicando ${\boldsymbol u}$ a $B$ si ottiene il vettore
$\overrightarrow{BC}$ con coda in $C$. Possiamo quindi &lt;em&gt;definire&lt;/em&gt;
$\overrightarrow{AC}$ come rappresentante del vettore geometrico somma
${\boldsymbol v}+{\boldsymbol u}$. La costruzione ora descritta
corrisponde ala cosiddetta &lt;em&gt;regola del parallelogramma&lt;/em&gt;, ed è
equivalente a considerare ${\boldsymbol u}$ e ${\boldsymbol v}$
applicati allo stesso punto $A$ e costrure su di essi un
parallelogramma, considerando quindi come somma la diagonale del
quadrilatero ottenuto:&lt;/p&gt;
&lt;img src=&#34;https://gsicuro.github.io/images/im2/main-1.jpg&#34; alt=&#34;Regola del parallelogramma&#34; style=&#34;width:40%;&#34;/&gt; 
&lt;p&gt;È evidente dalla costruzione stessa che l&amp;rsquo;operazione è commutativa,
ovvero
${\boldsymbol v}+{\boldsymbol u}={\boldsymbol u}+{\boldsymbol v}$, e
tale per cui ${\boldsymbol v}+\mathbf 0={\boldsymbol v}$. L&amp;rsquo;operazione
di somma che abbiamo definito è anche &lt;em&gt;associativa&lt;/em&gt;. Se abbiamo tre
vettori ${\boldsymbol v}$, ${\boldsymbol u}$ e ${\boldsymbol w}$, allora&lt;/p&gt;
&lt;img src=&#34;https://gsicuro.github.io/images/im2/somma.png&#34; alt=&#34;Associatività&#34; style=&#34;width:80%;&#34;/&gt; 
&lt;p&gt;Infine, dato un vettore applicato $\overrightarrow{AB}$, il vettore
applicato $\overrightarrow{BA}$ è tale per cui
$\overrightarrow{AB}+\overrightarrow{BA}=\mathbf 0$: se il vettore
geometrico associato a $\overrightarrow{AB}$ è ${\boldsymbol v}$,
denotiamo quindi $-{\boldsymbol v}$ il vettore geometrico associato a
$\overrightarrow{BA}$ e scriviamo
${\boldsymbol v}+(-{\boldsymbol v})=\mathbf 0$: $-{\boldsymbol v}$ è
l&amp;rsquo;&lt;em&gt;opposto&lt;/em&gt; di ${\boldsymbol v}$.&lt;/p&gt;
&lt;p&gt;È possibile anche introdurre l&amp;rsquo;operazione &lt;em&gt;moltiplicazione per uno
scalare $c\in{\mathbb R}$&lt;/em&gt;: il vettore $c{\boldsymbol v}$ ha stessa
direzione di ${\boldsymbol v}$, stesso verso se $c&amp;gt;0$ e verso opposto se
$c&amp;lt;0$, e lunghezza uguale a $|c|$ volte quella di ${\boldsymbol v}$.&lt;/p&gt;
&lt;p&gt;Se $c=0$, allora $c{\boldsymbol v}=\mathbf 0$. È facile verificare che,
se $a,b\in{\mathbb R}$, allora
$(a+b){\boldsymbol v}=a{\boldsymbol v}+b{\boldsymbol v}$,
$(ab){\boldsymbol v}=a(b{\boldsymbol v})$ e, dati due vettori
${\boldsymbol v}$ e ${\boldsymbol u}$,
$a({\boldsymbol v}+{\boldsymbol u})=a{\boldsymbol v}+a{\boldsymbol u}$.&lt;/p&gt;
&lt;h3 id=&#34;spazi-vettoriali&#34;&gt;Spazi vettoriali&lt;/h3&gt;
&lt;p&gt;Lo spazio dei vettori geometrici può avere una interpretazione intuitiva
abbastanza semplice. Può rappresentare, per esempio, lo spazio degli
&lt;em&gt;spostamenti&lt;/em&gt; nel piano. Tuttavia la sua struttura può essere
generalizzata in forma astratta: essa è caratterizzata dalla presenza di
due operazioni binarie (somma tra vettori e prodotto per scalare) e lo
&lt;em&gt;spazio vettoriale&lt;/em&gt; dei vettori geometrici è stato introdotto proprio
per mezzo di queste operazioni.&lt;/p&gt;
&lt;p&gt;L&amp;rsquo;idea ora è tentare di caratterizzare cosa sia uno spazio vettoriale
senza necessariamente avere in mente una rappresentazione pittorica. In
generale, la costruzione di uno spazio vettoriale richiede l&amp;rsquo;esistenza
di un insieme $\mathbb V$ di &amp;ldquo;vettori&amp;rdquo; e di un altro insieme di
&amp;ldquo;scalari&amp;rdquo;, ${\mathbb K}$. Ci limiteremo ad assumere che ${\mathbb K}$
sia, a seconda dei casi ${\mathbb Q}$, ${\mathbb R}$ o ${\mathbb C}$, ma
utilizzeremo ${\mathbb K}$ per lavorare in maggiore generalità.&lt;/p&gt;
&lt;p&gt;Il concetto di spazio vettoriale può quindi essere formalizzato come
segue.&lt;/p&gt;
&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt; &lt;b&gt; Definizione &lt;/b&gt;
Uno spazio vettoriale su un campo
${\mathbb K}$ è un insieme non vuoto $\mathbb V$ tale per cui esistono
due operazioni binarie, ovvero
$+\colon\mathbb V\times\mathbb V\to\mathbb V$, detta &lt;i&gt;somma&lt;/i&gt;, e
$\cdot \colon{\mathbb K}\times\mathbb V\to\mathbb V$, detta &lt;i&gt;prodotto
per uno scalare&lt;/i&gt;, con le seguenti proprietà:
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;la somma $+$ è commutativa e associativa; esiste un elemento neutro
$\mathbf 0$, ovvero se ${\boldsymbol v}\in\mathbb V$, allora
${\boldsymbol v}+\mathbf 0=\mathbf 0+{\boldsymbol v}={\boldsymbol v}$;
esiste l&amp;rsquo;elemento opposto, ovvero se ${\boldsymbol v}\in\mathbb V$
esiste $-{\boldsymbol v}\in\mathbb V$ tale per cui
${\boldsymbol v}+(-{\boldsymbol v})=\mathbf 0$;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;il prodotto $\cdot$ è distributivo sulla somma di vettori (ovvero
$a({\boldsymbol v}+{\boldsymbol u})=a{\boldsymbol v}+a{\boldsymbol u}$
per $a\in{\mathbb K}$ e
${\boldsymbol v},{\boldsymbol u}\in\mathbb V$) e sulla somma di
scalari (ovvero
$(a+b){\boldsymbol v}=a{\boldsymbol v}+b{\boldsymbol v}$ per
$a,b\in{\mathbb K}$ e ${\boldsymbol v}\mathbb V$); infine l&amp;rsquo;elemento
neutro $1$ di ${\mathbb K}$ è tale per cui
$1{\boldsymbol v}={\boldsymbol v}$.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;La definizione precedente si applica in effetti ai vettori geometrici,
ed è anzi ispirata da essi. Come potete notare, è richiesto che
${\mathbb K}$ sia un &lt;a href=&#34;https://it.wikipedia.org/wiki/Campo_%28matematica%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;campo&lt;/em&gt;&lt;/a&gt;: come anticipato, per semplicità assumeremo
che ${\mathbb K}$ sia un campo numerico come ${\mathbb R}$,
${\mathbb Q}$ e ${\mathbb C}$.&lt;/p&gt;
&lt;div class=&#34;alert alert-success&#34; role=&#34;alert&#34;&gt;
Un esempio di spazio vettoriale è dato dai vettori nel piano
$\mathbb V={\mathbb R}^2$. Un vettore nel piano ${\boldsymbol x}$ è
rappresentato da una freccia applicata nell&#39;origine che punta in una
posizione del piano
&lt;img src=&#34;https://gsicuro.github.io/images/im2/main-5.jpg&#34; alt=&#34;Vettore nel piano&#34; style=&#34;width:50%;&#34;/&gt; 
&lt;p&gt;e può rappresentarsi come una coppia di numeri come
$${\boldsymbol x}=
\begin{pmatrix}
x_1\\ x_2
\end{pmatrix}
\in{\mathbb R}^2,$$
corrispondenti alle sue coordinate. Dati due vettori ${\boldsymbol x}_1$
e ${\boldsymbol x}_2$, una loro combinazione lineare con coefficienti
reali $c_1$ e $c_2$ si ottiene come
$${\boldsymbol x}_1=
\begin{pmatrix}
x_{11}\\x_{12}
\end{pmatrix}
,\quad  {\boldsymbol x}_2=
\begin{pmatrix}
x_{21}\\x_{22}
\end{pmatrix}
\Rightarrow c_1{\boldsymbol x}_1+c_2{\boldsymbol x}_2=
\begin{pmatrix}
c_1x_{11}+c_2x_{21}\\c_1x_{12}+c_2x_{22}
\end{pmatrix}.$$
Per esempio, nella figura sotto ${\boldsymbol x}_1=\binom{3}{1}$ e
${\boldsymbol x}_2=\binom{1}{4}$, ed in rosso è rappresentata la loro
somma $2{\boldsymbol x}_1+{\boldsymbol x}_2=\binom{7}{6}$.&lt;/p&gt;
&lt;img src=&#34;https://gsicuro.github.io/images/im2/main-6.jpg&#34; alt=&#34;Somma di vettori nel piano&#34; style=&#34;width:50%;&#34;/&gt; 
&lt;/div&gt;
&lt;p&gt;Se ${\boldsymbol v}_1,\dots,{\boldsymbol v}_k\in\mathbb V$ e
$c_1,\dots,c_k\in{\mathbb K}$, il vettore
${\boldsymbol v}=c_1{\boldsymbol v}_1+\dots+c_k{\boldsymbol v}_k\in\mathbb V$
si dice essere una combinazione lineare di
${\boldsymbol v}_1,\dots,{\boldsymbol v}_k$ a coefficienti
$c_1,\dots,c_k$. Il concetto di combinazione lineare è cruciale e
caratterizza le proprietà di uno spazio vettoriale. Con un leggero
abuso, utilizzeremo la notazione&lt;/p&gt;
&lt;p&gt;$$c_1{\boldsymbol v}_1+\dots+c_k{\boldsymbol v}_k\equiv \sum_{i=1}^kc_i{\boldsymbol v}_i.$$&lt;/p&gt;
&lt;p&gt;Chiamiamo l&amp;rsquo;insieme di tutte le combinazioni lineari dei vettori
$\mathcal V\equiv \{{\boldsymbol v}_i\}_{i=1}^k$ lo &lt;em&gt;span&lt;/em&gt; di
$\{{\boldsymbol v}_i\}_{i=1}^k$ e scriviamo $\mathrm{span}(\mathcal V)$.&lt;/p&gt;
&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt; &lt;b&gt; Definizione &lt;/b&gt;
I vettori $\{{\boldsymbol v}_i\}_{i=1}^k$ sono linearmente dipendenti se
esistono degli scalari $\{c_i\}_{i=1}^k$ non tutti nulli tali per cui
&lt;p&gt;$$\sum_{i=1}^kc_i{\boldsymbol v}_i=\mathbf 0;$$&lt;/p&gt;
&lt;p&gt;diversamente si dicono linearmente indipendenti.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Per definizione, il singolo vettore ${\boldsymbol v}$ è linearmente
dipendente se e solo se uguale al vettor nullo. Viceversa, se
${\boldsymbol v}_2=c{\boldsymbol v}_1$, ${\boldsymbol v}_1$ e
${\boldsymbol v}_2$ sono linearmente dipendenti. La definizione implica
che in un insieme di vettori linearmente dipendenti, almeno uno di essi
può sempre esprimersi come combinazione lineare degli altri. Infine,
vale la seguente proposizione.&lt;/p&gt;
&lt;div class=&#34;alert alert-danger&#34; role=&#34;alert&#34;&gt; &lt;b&gt; Proposizione &lt;/b&gt;
Se $\{{\boldsymbol v}_i\}_{i=1}^k$ sono linearmente indipendenti,
allora, dati due set di scalari in ${\mathbb K}$ $\{a_i\}_{i=1}^k$ e
$\{b_i\}_{i=1}^k$
$$\sum_{i=1}^ka_i{\boldsymbol v}_i=\sum_{i=1}^kb_i{\boldsymbol v}_i\Rightarrow a_i=b_i\ \forall i=1,\dots,k.$$
&lt;/div&gt;
&lt;p&gt;Infine, possiamo introdurre il concetto di &lt;em&gt;base&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt; &lt;b&gt; Definizione &lt;/b&gt;
Il set $\mathcal B\equiv \{{\boldsymbol v}_i\}_{i=1}^n$ di vettori di
$\mathbb V$ è una base se essi sono linearmente indipendenti e se
$\mathbb V=\mathrm{span}[\mathcal B]$.
&lt;/div&gt;
&lt;p&gt;Questo significa che ogni vettore ${\boldsymbol v}\in\mathbb V$ può
scriversi &lt;em&gt;in maniera unica&lt;/em&gt; come
${\boldsymbol v}=\sum_{i=1}^n c_i{\boldsymbol v}_i$, con coefficienti
$c_i$ che sono detti &lt;em&gt;coordinate&lt;/em&gt; di ${\boldsymbol v}$ secondo la base
$\mathcal B$. Ciò comporta anche che non è possibile avere un set di
vettori indipendenti con più di $n$ elementi. Vale infatti il seguente&lt;/p&gt;
&lt;div class=&#34;alert alert-danger&#34; role=&#34;alert&#34;&gt; &lt;b&gt; Teorema &lt;/b&gt;
Sia $\mathcal B\equiv  \{{\boldsymbol v}_i\}_{i=1}^n$ una base di
$\mathbb V$. Allora ogni set $\{{\boldsymbol u}_i\}_{i=1}^m$ di $m&gt;n$
vettori di $\mathbb V$ è costituito da elementi linearmente dipendenti.
Di conseguenza, ogni base di $\mathbb V$ ha $n$ elementi: il numero $n$
prende il nome di dimensione di $\mathbb V$.
&lt;/div&gt;
&lt;div class=&#34;alert alert-success&#34; role=&#34;alert&#34;&gt;
Lo spazio vettoriale ${\mathbb R}^n$ su ${\mathbb R}$ è costituito da
vettori $n$-dimensionali, rappresentabili come vettori colonna,
&lt;p&gt;$${\boldsymbol x}=\begin{pmatrix}x_1\\ \vdots\\x_n\end{pmatrix}.$$&lt;/p&gt;
&lt;p&gt;In questo caso è facilmente identificata una &lt;em&gt;base canonica&lt;/em&gt;
$\mathcal B=\{{\boldsymbol e}_i\}_{i=1}^n$ di $n$ vettori&lt;/p&gt;
&lt;p&gt;$${\boldsymbol e}_1\equiv
\begin{pmatrix}1\\0\\ \vdots\\0\end{pmatrix}
\quad{\boldsymbol e}_2\equiv
\begin{pmatrix}0\\1\\ \vdots\\0\end{pmatrix}
\quad\dots
\quad{\boldsymbol e}_n\equiv
\begin{pmatrix}0\\0\\ \vdots\\1\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;che permette di scrivere in maniera univoca qualunque vettore
${\boldsymbol x}\in{\mathbb R}^n$ come&lt;/p&gt;
&lt;p&gt;$${\boldsymbol x}=x_1
{\boldsymbol e}_1+\dots+
x_n{\boldsymbol e}_n.$$&lt;/p&gt;
&lt;/div&gt;
&lt;h4 id=&#34;sottospazi-vettoriali&#34;&gt;Sottospazi vettoriali&lt;/h4&gt;
&lt;p&gt;Dato uno spazio vettoriale $\mathbb V$, è possibile identificare in
alcuni casi un &lt;em&gt;sottospazio&lt;/em&gt; vettoriale ${\mathbb W}$, ovvero un
sottoinsieme di $\mathbb V$ che è chiuso sotto le operazioni di somma e
prodotto per uno scalare, ovvero&lt;/p&gt;
&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt; &lt;b&gt; Definizione &lt;/b&gt;
Dato uno ${\mathbb K}$-spazio vettoriale $\mathbb V$, un sottoinsieme
non vuoto $\mathbb W\subset\mathbb V$ è un sottospazio vettoriale di
$\mathbb V$ se, per ogni ${\boldsymbol w},{\boldsymbol w}&#39;\in\mathbb W$,
${\boldsymbol w}+{\boldsymbol w}&#39;\in\mathbb W$, e per ogni
$c\in{\mathbb K}$, se ${\boldsymbol w}\in\mathbb W$ allora
$c{\boldsymbol w}\in\mathbb W$.
&lt;/div&gt;
&lt;p&gt;Per esempio, se
$\mathcal V\equiv \subset\mathbb V$ è un sottoinsieme finito di $\mathbb V$,
$\mathrm{span}[\mathcal V]$ è un sottospazio di $\mathbb V$ (in
particolare, lo è anche per $\mathcal V$ ha cardinalità 1). Inoltre la dimensione di un
sottospazio è sempre limitata superiormente dalla dimensione dello
spazio in cui vive. È interessante notare che se $\mathbb U$ e
$\mathbb W$ sono sottospazi vettoriali di $\mathbb V$, allora
$\mathbb U\cap\mathbb W$ è anche sottospazio vettoriale di $\mathbb V$
(mentre la loro unione, in generale, non lo è).&lt;/p&gt;
&lt;p&gt;Dati due sottospazi vettoriali $\mathbb U$ e $\mathbb W$, se
$\mathbb U\cap\mathbb W={\mathbf 0}$ è possibile costruire un nuovo
spazio, detto &lt;em&gt;somma diretta di $\mathbb U$ e $\mathbb W$&lt;/em&gt; e indicato
con $\mathbb U\oplus\mathbb W$. Questo spazio consiste di tutti i
vettori ${\boldsymbol v}$ nella forma
${\boldsymbol v}={\boldsymbol u}+{\boldsymbol w}$ con
${\boldsymbol u}\in\mathbb U$, ${\boldsymbol w}\in\mathbb W$. Inoltre
questa decomposizione è unica: se infatti assumessimo che esiste
un&amp;rsquo;altra coppia tale per cui
${\boldsymbol v}={\boldsymbol u}&amp;rsquo;+{\boldsymbol w}&amp;rsquo;$, con
${\boldsymbol u}&amp;rsquo;\in\mathbb U$, ${\boldsymbol w}&amp;rsquo;\in\mathbb W$, allora
dovremmo avere
${\boldsymbol u}+{\boldsymbol w}={\boldsymbol u}&amp;rsquo;+{\boldsymbol w}&amp;rsquo;$ e
quindi
${\boldsymbol u}-{\boldsymbol u}&amp;rsquo;={\boldsymbol w}-{\boldsymbol w}&amp;rsquo;$. Ma
questa quantità può essere solo $\mathbf 0$, unico elemento
nell&amp;rsquo;intersezione dei due spazi.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Matrici</title>
      <link>https://gsicuro.github.io/lectures/im2/ch1/sec2/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/lectures/im2/ch1/sec2/</guid>
      <description>&lt;h2 id=&#34;matrici&#34;&gt;Matrici&lt;/h2&gt;
&lt;p&gt;Un esempio particolarmente importante e prototipico di spazio vettoriale
è costituito dallo spazio delle matrici di elementi in ${\mathbb K}$.
Consideriamo ora due interi positivi $m$ e $n$. Una &lt;em&gt;matrice&lt;/em&gt; di
$m\times n$ elementi in ${\mathbb K}$ è una tabella del tipo&lt;/p&gt;
&lt;p&gt;$${\boldsymbol A}=
\begin{pmatrix}a_{11}&amp;amp;a_{12}&amp;amp;\dots&amp;amp;a_{1n}\\
a_{21}&amp;amp;a_{22}&amp;amp;\dots&amp;amp;a_{2n}\\
\cdots&amp;amp;\cdots&amp;amp;\ddots&amp;amp;\vdots\\
a_{m1}&amp;amp;a_{m2}&amp;amp;\dots&amp;amp;a_{mn}
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;dove, $\forall \mu,\nu$, $a_{\mu\nu}\in{\mathbb K}$: il primo indice
denota la riga dell&amp;rsquo;elemento nella tabella, il secondo la sua colonna.
Scriveremo ${\boldsymbol A}=(a_{\mu\nu})_{\mu\nu}\in\mathcal M_{m,n}({\mathbb K})$.
A volte si denota&lt;/p&gt;
&lt;p&gt;$${\boldsymbol a}_\mu=(a_{\mu 1},\dots, a_{\mu n})$$&lt;/p&gt;
&lt;p&gt;la $\mu$-esima riga e&lt;/p&gt;
&lt;p&gt;$${\boldsymbol a}^\nu=\begin{pmatrix}a_{1\nu}\\ \dots\\a_{m\nu}
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;la $\nu$-esima colonna. Ogni matrice
${\boldsymbol A}$ può essere associata ad una matrice
${\boldsymbol A}^\intercal\in\mathcal M_{n,m}({\mathbb K})$ detta
&lt;em&gt;trasposta&lt;/em&gt; ottenuta invertendo righe con colonne:&lt;/p&gt;
&lt;p&gt;$${\boldsymbol A}=
\begin{pmatrix}a_{11}&amp;amp;a_{12}&amp;amp;\dots&amp;amp;a_{1n}\\
a_{21}&amp;amp;a_{22}&amp;amp;\dots&amp;amp;a_{2n}\\
\cdots&amp;amp;\cdots&amp;amp;\ddots&amp;amp;\vdots\\
a_{m1}&amp;amp;a_{m2}&amp;amp;\dots&amp;amp;a_{mn}
\end{pmatrix}
\Rightarrow {\boldsymbol A}^\intercal=
\begin{pmatrix}a_{11}&amp;amp;a_{21}&amp;amp;\dots&amp;amp;a_{m1}\\
a_{12}&amp;amp;a_{22}&amp;amp;\dots&amp;amp;a_{m2}\\
\cdots&amp;amp;\cdots&amp;amp;\ddots&amp;amp;\vdots\\
a_{1n}&amp;amp;a_{2n}&amp;amp;\dots&amp;amp;a_{mn}
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;L&amp;rsquo;operazione di trasposizione è quindi tale che
$\intercal\colon\mathcal M_{n,m}({\mathbb K})\to \mathcal M_{m,n}({\mathbb K})$.
Matrici con $n=1$ sono in particolare dette &lt;em&gt;vettori colonna&lt;/em&gt;, e viene
tipicamente usata la notazione
$\mathcal M_{m,1}({\mathbb K})\equiv {\mathbb K}^m$. Lo spazio delle
matrici su $\mathcal M_{m,n}({\mathbb K})$ costituisce uno spazio
vettoriale se introduciamo le seguenti operazioni. Date due matrici
${\boldsymbol A}=(a_{\mu\nu})&lt;em&gt;{\mu\nu},{\boldsymbol B}=(b&lt;/em&gt;{\mu\nu})&lt;em&gt;{\mu\nu}\in \mathcal M&lt;/em&gt;{m,n}({\mathbb K})$,
e uno scalare $c\in{\mathbb K}$, allora definiamo&lt;/p&gt;
&lt;p&gt;$${\boldsymbol A}+{\boldsymbol B}\equiv  (a_{\mu\nu}+b_{\mu\nu})&lt;em&gt;{\mu\nu}\in \mathcal M&lt;/em&gt;{m,n}({\mathbb K}),\qquad c{\boldsymbol A}\equiv  (ca_{\mu\nu})&lt;em&gt;{\mu\nu}\in\mathcal M&lt;/em&gt;{m,n}({\mathbb K}).$$&lt;/p&gt;
&lt;p&gt;Queste operazioni soddisfano le proprietà richieste per rendere
$\mathcal M_{m,n}({\mathbb K})$ uno spazio vettoriale secondo la
Definizione
&lt;a href=&#34;#def:spaziovettoriale&#34;&gt;[def:spaziovettoriale]&lt;/a&gt;{reference-type=&amp;ldquo;ref&amp;rdquo;
reference=&amp;ldquo;def:spaziovettoriale&amp;rdquo;}. Questo spazio ha dimensione $mn$. Una
base è costuita dalle matrici
${\boldsymbol E}&lt;em&gt;{ij}=(\delta&lt;/em&gt;{i\mu}\delta_{j\nu})_{\mu\nu}$.&lt;/p&gt;
&lt;h3 id=&#34;prodotto-tra-matrici&#34;&gt;Prodotto tra matrici&lt;/h3&gt;
&lt;p&gt;È possibile definire ora una nuova operazione, quella di &lt;em&gt;prodotto tra
matrici&lt;/em&gt;. Consideriamo una matrice
${\boldsymbol A}\in\mathcal M_{n,k}({\mathbb K})$ e una matrice
${\boldsymbol B}\in\mathcal M_{k,m}({\mathbb K})$. Allora è possibile
introdurre una matrice
${\boldsymbol C}=(c_{\mu\nu})&lt;em&gt;{\mu\nu}={\boldsymbol A}{\boldsymbol B}\in\mathcal M&lt;/em&gt;{n,m}({\mathbb K})$
tale che&lt;/p&gt;
&lt;p&gt;$$c_{\mu\nu}=\sum_{\rho=1}^ka_{\mu\rho}b_{\rho\nu}.$$&lt;/p&gt;
&lt;p&gt;In particolare, se ${\boldsymbol u}$ è un $n$-vettore riga&lt;/p&gt;
&lt;p&gt;$${\boldsymbol u}=
\begin{pmatrix}
u_1&amp;amp;\dots&amp;amp; u_n
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;e ${\boldsymbol v}$ un $n$-vettore colonna,&lt;/p&gt;
&lt;p&gt;$${\boldsymbol v}=
\begin{pmatrix}
v_1\\dots\ v_n
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;è possibile definire il &lt;em&gt;prodotto scalare&lt;/em&gt; tra i due come&lt;/p&gt;
&lt;p&gt;$${\boldsymbol u}{\boldsymbol v}=\sum_{\nu=1}^n u_\nu v_\nu.$$&lt;/p&gt;
&lt;p&gt;Nel caso dei vettori colonna, in particolare, si indica con
$|{\boldsymbol v}|^2\equiv {\boldsymbol v}^\intercal{\boldsymbol v}=\sum_{\nu=1}^nv_\nu^2$
la loro &lt;em&gt;norma&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Notare che l&amp;rsquo;operazione di prodotto tra matrici &lt;em&gt;non è abeliana&lt;/em&gt; e anzi
se $n\neq m$ il prodotto ${\boldsymbol B}{\boldsymbol A}$ è non
definito. Anche qualora l&amp;rsquo;operazione fosse possibile, per esempio se
$n=m$,
${\boldsymbol A}{\boldsymbol B}\neq {\boldsymbol B}{\boldsymbol A}$ in
generale.&lt;/p&gt;
&lt;p&gt;Le proprietà del prodotto tra matrici sono date dalla seguente
Proposizione, la cui dimostrazione avviene controllando esplicitamente
la validità di ogni affermazione.&lt;/p&gt;
&lt;p&gt;Siano ${\boldsymbol A},{\boldsymbol B}\in\mathcal M_{m,n}({\mathbb K})$
e ${\boldsymbol C},{\boldsymbol D}\in\mathcal M_{n,p}({\mathbb K})$, e
sia $c\in{\mathbb K}$. Allora&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$({\boldsymbol A}+{\boldsymbol B}){\boldsymbol C}={\boldsymbol A}{\boldsymbol C}+{\boldsymbol B}{\boldsymbol C}$;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;${\boldsymbol A}({\boldsymbol C}+{\boldsymbol D})={\boldsymbol A}{\boldsymbol C}+{\boldsymbol A}{\boldsymbol D}$;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;${\boldsymbol A}(c{\boldsymbol C})=c({\boldsymbol A}{\boldsymbol C})=(c{\boldsymbol A}){\boldsymbol C}$;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;${\boldsymbol A}{\boldsymbol I}_n={\boldsymbol A}={\boldsymbol I}_m{\boldsymbol A}$;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$({\boldsymbol A}{\boldsymbol C})^\intercal={\boldsymbol C}^\intercal{\boldsymbol A}^\intercal$;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$({\boldsymbol A}+{\boldsymbol B})^\intercal={\boldsymbol A}^\intercal+{\boldsymbol B}^\intercal$;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$({\boldsymbol A}{\boldsymbol C}){\boldsymbol Q}={\boldsymbol A}({\boldsymbol C}{\boldsymbol Q})$
se ${\boldsymbol Q}\in{\mathbb K}^{p\times q}$.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;matrici-quadrate&#34;&gt;Matrici quadrate&lt;/h3&gt;
&lt;p&gt;Data una matrice ${\boldsymbol A}\in\mathcal M_{m,n}({\mathbb K})$, se
$m=n$ la matrice ${\boldsymbol A}$ è detta &lt;em&gt;quadrata&lt;/em&gt; di dimensione $n$.
Una matrice quadrata è diagonale se ha la forma
${\boldsymbol A}=(a_{\mu}\delta_{\mu\nu})&lt;em&gt;{\mu\nu}$, dove
$\delta&lt;/em&gt;{\mu\nu}$ è il simbolo di Kronecker. Tra le matrici diagonali la
&lt;em&gt;matrice unità&lt;/em&gt; ${\boldsymbol I}&lt;em&gt;n\equiv (\delta&lt;/em&gt;{\mu\nu})_{\mu\nu}$
ha un ruolo speciale dato che si comporta come l&amp;rsquo;identità rispetto al
prodotto tra matrici, come vedremo. Infine, una matrice quadrata
${\boldsymbol A}\in{\mathbb K}$ è &lt;em&gt;simmetrica&lt;/em&gt; se
${\boldsymbol A}={\boldsymbol A}^\intercal$ e &lt;em&gt;antisimmetrica&lt;/em&gt; se
${\boldsymbol A}=-{\boldsymbol A}^\intercal$. Elenchiamo ora alcune
proprietà delle matrici quadrate.&lt;/p&gt;
&lt;p&gt;Una matrice quadrata ${\boldsymbol A}\in\mathcal M_{n,n}({\mathbb K})$
si dice invertibile se esiste una matrice quadrata $n\times n$, che
denotiamo con ${\boldsymbol A}^{-1}$, tale che
${\boldsymbol A}{\boldsymbol A}^{-1}={\boldsymbol A}^{-1}{\boldsymbol A}={\boldsymbol I}_n$.&lt;/p&gt;
&lt;p&gt;Sia ${\boldsymbol A}\in\mathcal M_{n,n}({\mathbb K})$. La sua matrice
inversa ${\boldsymbol A}^{-1}$ se esiste è unica.&lt;/p&gt;
&lt;p&gt;Supponiamo che la tesi non sia vera e procediamo per assurdo, ovvero
ammettiamo che esista una matrice
$\hat{\boldsymbol A}^{-1}\neq{\boldsymbol A}^{-1}$ tale che
$\hat{\boldsymbol A}^{-1}{\boldsymbol A}={\boldsymbol I}_n$. Allora
${\boldsymbol A}^{-1}={\boldsymbol A}^{-1}{\boldsymbol A}\hat{\boldsymbol A}^{-1}=\hat{\boldsymbol A}^{-1}$
che è l&amp;rsquo;assurdo cercato.&lt;/p&gt;
&lt;p&gt;Dalla definizione, $({\boldsymbol A}^{-1})^{-1}={\boldsymbol A}$ e
inoltre ${\boldsymbol I}^{-1}_n={\boldsymbol I}_n$. Infine, vale la
seguente&lt;/p&gt;
&lt;p&gt;Siano ${\boldsymbol A}\in\mathcal M_{n,p}({\mathbb K})$ e
${\boldsymbol B}\in{\mathbb K}^{p\times m}$ entrambe dotate di inversa.
Allora
$({\boldsymbol A}{\boldsymbol B})^{-1}={\boldsymbol B}^{-1}{\boldsymbol A}^{-1}\in\mathcal M_{m,n}({\mathbb K})$.&lt;/p&gt;
&lt;p&gt;Il sottoinsieme di $\mathcal M_{n,n}({\mathbb K})$ dato dalle matrici
invertibili si denota $\mathsf{GL}_{n}({\mathbb K})$ ed ha la struttura
di &lt;em&gt;gruppo&lt;/em&gt;. Se ${\mathbb K}={\mathbb R}$, all&amp;rsquo;interno di tale
sottinsieme si trova il sottinsieme $\mathsf O_n({\mathbb R})$ delle
matrici &lt;em&gt;ortogonali&lt;/em&gt;, ovvero delle matrici ${\boldsymbol A}$ tali per
cui ${\boldsymbol A}^{-1}={\boldsymbol A}^\intercal$.&lt;/p&gt;
&lt;p&gt;Concludiamo questa sezione sulle matrici quadrate introducendo un&amp;rsquo;ultima
importante quantità, ovvero il &lt;em&gt;determinante&lt;/em&gt; di una matrice quadrata.&lt;/p&gt;
&lt;p&gt;Data una matrice quadrata
${\boldsymbol A}\in\mathcal M_{n,n}({\mathbb K})$, il determinante di
${\boldsymbol A}$ è uno scalare in ${\mathbb K}$ definito ricorsivamente
come&lt;/p&gt;
&lt;p&gt;$$\det{\boldsymbol A}=\sum_{\mu\nu}(-1)^{\mu+\nu} a_{\mu\nu}\det({\boldsymbol A}_{\mu\nu})$$&lt;/p&gt;
&lt;p&gt;dove ${\boldsymbol A}_{\mu\nu}\in{\mathbb K}^{(n-1)\times(n-1)}$ è la
matrice $(n-1)\times (n-1)$ ottenuta da ${\boldsymbol A}$ rimuovendo la
$\mu$ riga e la $\nu$ colonna. Inoltre, dato uno scalare
$c\in{\mathbb K}$, $\det(c)=c$.&lt;/p&gt;
&lt;p&gt;La definizione sopra, dovuta a Laplace, è ricorsiva ma permette di
ottenere l&amp;rsquo;espressione del determinante in tutti i casi. Per esempio,
per $n=2$&lt;/p&gt;
&lt;p&gt;$$\det
\begin{pmatrix}
a_{11}&amp;amp;a_{12}\
a_{21}&amp;amp;a_{22}
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;=a_{11}a_{22}-a_{12}a_{21}.$$&lt;/p&gt;
&lt;p&gt;Nonostante la sua definizione apparentemente esotica, il determinante è,
come espresso dal nome, cruciale per comprendere molte proprietà delle
matrici quadrate. Esso stesso gode di alcune proprietà riassunte nel
seguente&lt;/p&gt;
&lt;p&gt;[[t:LinAlg:det]]{#t:LinAlg:det label=&amp;ldquo;t:LinAlg:det&amp;rdquo;} Sia
${\boldsymbol A}\in\mathcal M_{n\times n}({\mathbb K})$. Allora&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;se ${\boldsymbol A}$ è una matrice diagonale, allora
$\det{\boldsymbol A}=\prod_{i=1}^n a_{ii}$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\det{\boldsymbol A}=\det{\boldsymbol A}^\intercal$ (e di
conseguenza proprietà riferite alle colonne si applicano anche alle
righe).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dato uno scalare $c\in{\mathbb K}$,
$\det (c{\boldsymbol A}) = c^n \det{\boldsymbol A}$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sia una colonna di ${\boldsymbol A}$ tale che
${\boldsymbol a}^\nu=\lambda{\boldsymbol v}+{\boldsymbol u}$, i.e.,
$a_{\mu\nu}=\lambda v_\nu+u_\nu$. Allora&lt;/p&gt;
&lt;p&gt;$$\begin{gathered}
\det{\boldsymbol A}=\det
\left(
\begin{array}{cc&amp;gt;{\columncolor{gray!40}}ccc}
a_{11} &amp;amp; \dots &amp;amp; a_{1\nu} &amp;amp; \dots &amp;amp; a_{1n} \
\vdots &amp;amp;\vdots &amp;amp;\vdots&amp;amp;\vdots &amp;amp; \vdots\
a_{n1}&amp;amp;\cdots &amp;amp;a_{n\nu} &amp;amp;\cdots &amp;amp;a_{nn}
\end{array}&lt;/p&gt;
&lt;p&gt;\right)\=\lambda\det
\left(
\begin{array}{cc&amp;gt;{\columncolor{gray!40}}ccc}
a_{11} &amp;amp; \dots &amp;amp; v_{1} &amp;amp; \cdots &amp;amp; a_{1n} \
\vdots &amp;amp;\vdots &amp;amp;\vdots&amp;amp;\vdots &amp;amp; \vdots\
a_{n1}&amp;amp;\cdots &amp;amp;v_{n} &amp;amp;\cdots &amp;amp;a_{nn}
\end{array}&lt;/p&gt;
&lt;p&gt;\right)+\det
\left(
\begin{array}{cc&amp;gt;{\columncolor{gray!40}}ccc}
a_{11} &amp;amp; \dots &amp;amp; u_{1} &amp;amp; \dots &amp;amp; a_{1n} \
\vdots &amp;amp;\vdots &amp;amp;\vdots&amp;amp;\vdots &amp;amp; \vdots\
a_{n1}&amp;amp;\cdots &amp;amp;u_{n} &amp;amp;\cdots &amp;amp;a_{nn}
\end{array}&lt;/p&gt;
&lt;p&gt;\right)\end{gathered}
$$&lt;/p&gt;
&lt;p&gt;Si dice che di conseguenza il determinante è &lt;em&gt;multilineare&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Se ${\boldsymbol A}$ ha due colonne identiche,
$\det{\boldsymbol A}=0$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sia ${\boldsymbol B}\in\mathcal M_{n\times n}({\mathbb K})$; allora
$\det {\boldsymbol A}{\boldsymbol B}=\det{\boldsymbol A}\det {\boldsymbol B}$.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Una delle conseguenze delle proprietà suddette è che il determinante è
&lt;em&gt;alternante&lt;/em&gt;, ovvero guadagna un segno se due colonne vengono scambiate:&lt;/p&gt;
&lt;p&gt;$$\begin{gathered}
\det
\left(
\begin{array}{cc&amp;gt;{\columncolor{gray!20}}cc&amp;gt;{\columncolor{gray!60}}ccc}
a_{11} &amp;amp; \dots &amp;amp; a_{1k} &amp;amp;\dots &amp;amp; a_{1k&amp;rsquo;} &amp;amp; \dots &amp;amp; a_{1n} \
\vdots &amp;amp;\vdots &amp;amp;\vdots&amp;amp;\vdots &amp;amp; \vdots&amp;amp;\vdots &amp;amp; \vdots\
a_{n1}&amp;amp;\cdots &amp;amp;a_{nk} &amp;amp;\cdots &amp;amp;a_{nk&amp;rsquo;}&amp;amp;\cdots &amp;amp; a_{nn}
\end{array}&lt;/p&gt;
&lt;p&gt;\right)\=-\det
\left(
\begin{array}{cc&amp;gt;{\columncolor{gray!60}}cc&amp;gt;{\columncolor{gray!20}}ccc}
a_{11} &amp;amp; \dots &amp;amp; a_{1k&amp;rsquo;} &amp;amp;\dots &amp;amp; a_{1k} &amp;amp; \dots &amp;amp; a_{1n} \
\vdots &amp;amp;\vdots &amp;amp;\vdots&amp;amp;\vdots &amp;amp; \vdots&amp;amp;\vdots &amp;amp; \vdots\
a_{n1}&amp;amp;\cdots &amp;amp;a_{nk&amp;rsquo;} &amp;amp;\cdots &amp;amp;a_{nk}&amp;amp;\cdots &amp;amp; a_{nn}
\end{array}&lt;/p&gt;
&lt;p&gt;\right)\end{gathered}
$$&lt;/p&gt;
&lt;p&gt;Il ruolo cruciale del determinante è legato anche al seguente lemma che
caratterizza l&amp;rsquo;invertibilità delle matrici quadrate.&lt;/p&gt;
&lt;p&gt;[[l:LinAlg1:inv]]{#l:LinAlg1:inv label=&amp;ldquo;l:LinAlg1:inv&amp;rdquo;} Sia
${\boldsymbol A}\in\mathcal M_{n\times n}({\mathbb K})$; sia
${\boldsymbol C}$ la matrice dei suoi &lt;em&gt;cofattori&lt;/em&gt;, ovvero la matrice
$n\times n$ con elementi&lt;/p&gt;
&lt;p&gt;$$c_{\mu\nu} = (-1)^{\mu\nu}\det{\boldsymbol A}_{\mu\nu}.$$ Allora, se
$\det{\boldsymbol A}\neq 0$, l&amp;rsquo;inversa di ${\boldsymbol A}$ esiste ed è
data da&lt;/p&gt;
&lt;p&gt;$${\boldsymbol A}^{-1} = \frac{1}{\det{\boldsymbol A}} {\boldsymbol C}^\intercal.$$&lt;/p&gt;
&lt;h2 id=&#34;sistemi-di-equazioni-lineari&#34;&gt;Sistemi di equazioni lineari&lt;/h2&gt;
&lt;p&gt;Le definizioni date finora sono funzionali ad una serie di importanti
applicazioni. La prima che andremo a considerare è la soluzione di
&lt;em&gt;sistemi lineari di equazioni&lt;/em&gt;, ovvero sistemi nella forma&lt;/p&gt;
&lt;p&gt;$$\label{eq:linsyst}&lt;/p&gt;
&lt;p&gt;\begin{cases}
a_{11}x_1+a_{12}x_2+\dots+a_{1n}x_n=b_1\
a_{21}x_1+a_{22}x_2+\dots+a_{2n}x_n=b_2\
\vdots\
a_{m1}x_1+a_{m2}x_2+\dots+a_{mn}x_n=b_m
\end{cases}
$$&lt;/p&gt;
&lt;p&gt;in cui si assume che i coefficienti $a_{\mu\nu}\in{\mathbb K}$ e
$b_\nu\in{\mathbb K}$ siano noti e l&amp;rsquo;obiettivo è ottenere
$x_\nu\in{\mathbb K}$. Indicando con
${\boldsymbol A}=(a_{\mu\nu})&lt;em&gt;{\mu\nu}\in\mathcal M&lt;/em&gt;{m,n}({\mathbb K})$,
${\boldsymbol b}=(b_\nu)&lt;em&gt;\nu\in{\mathbb K}^m$,
${\boldsymbol x}=(x&lt;/em&gt;\nu)_{\nu}\in{\mathbb K}^n$, possiamo scrivere il
sistema sopra in una forma molto più compatta come&lt;/p&gt;
&lt;p&gt;$${\boldsymbol A}{\boldsymbol x}={\boldsymbol b}.$$&lt;/p&gt;
&lt;p&gt;Il sistema di equazioni è detto &lt;em&gt;omogeneo&lt;/em&gt; se
${\boldsymbol b}=\mathbf 0$, mentre diversamente è detto &lt;em&gt;non omogeneo&lt;/em&gt;.
Ogni sistema è detto &lt;em&gt;compatibile&lt;/em&gt; se ha almeno una soluzione: notare
che un sistema omogeneo ha sempre la soluzione &lt;em&gt;banale&lt;/em&gt;
${\boldsymbol x}=\mathbf 0$. Se è dato un sistema non omogeneo
${\boldsymbol A}{\boldsymbol x}={\boldsymbol b}$,
${\boldsymbol b}\neq\mathbf 0$, allora il sistema omogeneo ad esso
associato è ${\boldsymbol A}{\boldsymbol x}=\mathbf 0$.&lt;/p&gt;
&lt;h3 id=&#34;metodo-di-eliminazione-di-gauss&#34;&gt;Metodo di eliminazione di Gauss&lt;/h3&gt;
&lt;p&gt;Risolvere un sistema tipo
${\boldsymbol A}{\boldsymbol x}={\boldsymbol b}$ è il problema centrale
dell&amp;rsquo;algebra lineare. L&amp;rsquo;idea generale è utilizzare operazioni matriciali
per poter infine ottenere una espressione per la soluzione
${\boldsymbol x}$, se essa esiste. Un primo approccio che possiamo
tentare è il cosiddetto metodo di eliminazione di Gauss. Supponiamo di
avere un sistema come in
Eq. &lt;a href=&#34;#eq:linsyst&#34;&gt;[eq:linsyst]&lt;/a&gt;{reference-type=&amp;ldquo;eqref&amp;rdquo;
reference=&amp;ldquo;eq:linsyst&amp;rdquo;}. Questo può essere associato alla seguente
matrice&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
a_{11}&amp;amp;a_{12}&amp;amp;\dots&amp;amp;a_{1n}&amp;amp;b_1\\
a_{21}&amp;amp;a_{22}&amp;amp;\dots&amp;amp;a_{2n}&amp;amp;b_2\\
\cdots&amp;amp;\cdots&amp;amp;\ddots&amp;amp;\vdots\\
a_{m1}&amp;amp;a_{m2}&amp;amp;\dots&amp;amp;a_{mn}&amp;amp;b_m
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;ottenuta concatenando la matrice ${\boldsymbol A}$ e la colonna
${\boldsymbol b}$ e talvolta detta &lt;em&gt;matrice orlata&lt;/em&gt;. Ogni matrice
siffatta corrisponde ad un sistema come in
Eq. &lt;a href=&#34;#eq:linsyst&#34;&gt;[eq:linsyst]&lt;/a&gt;{reference-type=&amp;ldquo;eqref&amp;rdquo;
reference=&amp;ldquo;eq:linsyst&amp;rdquo;}. Possiamo eseguire una serie di operazioni di
riga su questa matrice che lasciano inalterato il problema. In
particolare&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;possiamo moltiplicare una riga per una costante $c\in{\mathbb K}$
che sia non nulla;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;possiamo scambiare due righe;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;possiamo aggiungere ad una riga un multiplo di un&amp;rsquo;altra riga.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Questo tipo di operazioni può essere utilizzato per risolvere il sistema
di equazioni lineari. Vediamo come con un esempio.&lt;/p&gt;
&lt;p&gt;Cerchiamo di risolvere il sistema&lt;/p&gt;
&lt;p&gt;$$\begin{cases}
2x_1+4x_2-2x_3=2\
4x_1+9x_2-3x_3=8\
-2x_1-3x_2+7x_3=10
\end{cases}&lt;/p&gt;
&lt;p&gt;\Leftrightarrow&lt;/p&gt;
&lt;p&gt;\begin{pmatrix}
2&amp;amp;4&amp;amp;-2\
4&amp;amp;9&amp;amp;-3\
-2&amp;amp;-3&amp;amp;7
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;\begin{pmatrix}
x_1\x_2\x_3
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;=
\begin{pmatrix}2\8\10
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;così che la matrice orlata è&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
2&amp;amp;4&amp;amp;-2&amp;amp;2\
4&amp;amp;9&amp;amp;-3&amp;amp;8\
-2&amp;amp;-3&amp;amp;7&amp;amp;10
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Proviamo ora a eseguire una operazione tale per cui la variabile $x_1$
venga rimossa da tutte le equazioni eccetto la prima. Ciò equivale a
dire che gli elementi sotto $a_{11}$ devono essere trasformati in zero
eseguendo una delle operazioni di riga indicate sopra. Per esempio,
sostituiamo la $i$-esima riga con
$(\text{$i$ riga})-\frac{a_{i1}}{a_{11}}(\text{prima riga})$. L&amp;rsquo;elemento
$a_{11}$ è detto &lt;em&gt;primo pivot&lt;/em&gt; ed è cruciale che non sia zero. Se
dovesse esserlo, basta scambiare le righe in maniera tale che compaia
come prima una riga con $a_{11}\neq 0$. Si ottiene quindi&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
2&amp;amp;4&amp;amp;-2&amp;amp;2\
0&amp;amp;1&amp;amp;1&amp;amp;4\
0&amp;amp;1&amp;amp;5&amp;amp;12
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Ripetiamo la procedura partendo dalla &lt;em&gt;seconda&lt;/em&gt; riga verso il basso.
Questa volta il pivot è $a_{22}=1$ e si procede come sopra per le righe
$i&amp;gt;2$: $(\text{$i$ riga})-\frac{a_{i2}}{a_{22}}(\text{prima riga})$,
ottenendo&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
2&amp;amp;4&amp;amp;-2&amp;amp;2\
0&amp;amp;1&amp;amp;1&amp;amp;4\
0&amp;amp;0&amp;amp;4&amp;amp;8
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Questa matrice è a gradini e siamo arrivati alla forma desiderata.
Perché questo è utile? Se scriviamo il sistema associato, esso è&lt;/p&gt;
&lt;p&gt;$$\begin{cases}
2x_1+4x_2-2x_3=2\
x_2+x_3=4\
4x_3=8
\end{cases}
$$&lt;/p&gt;
&lt;p&gt;che può essere risolto all&amp;rsquo;indietro, ovvero risolvendo prima per $x_3$,
ottenendo $x_3=2$, la cui soluzione può essere sostituita nella seconda
riga che dà $x_2=2$ e infine inserendo entrambe queste soluzioni nella
prima, che fornisce $x_1=-1$.&lt;/p&gt;
&lt;p&gt;L&amp;rsquo;idea del &lt;em&gt;metodo di eliminazione di Gauss&lt;/em&gt; consiste quindi nel
trasformare la matrice orlata in una &lt;em&gt;matrice a gradini&lt;/em&gt; che ammetta più
facilmente una soluzione. Se $m\leq n$, tale matrice finale avrà la
forma&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
a_{11}&amp;amp;a_{12}&amp;amp;\dots&amp;amp;a_{1m}&amp;amp;\dots&amp;amp;a_{1n}&amp;amp;b_1\
0&amp;amp;a_{22}&amp;amp;\dots&amp;amp;a_{2m}&amp;amp;\dots&amp;amp;a_{2n}&amp;amp;b_2\
\vdots&amp;amp;\vdots&amp;amp;\ddots&amp;amp;\cdots&amp;amp;\cdots&amp;amp;\vdots&amp;amp;\vdots\
0&amp;amp;0&amp;amp;\dots&amp;amp;a_{mm}&amp;amp;\dots&amp;amp;a_{mn}&amp;amp;b_m
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;.$$&lt;/p&gt;
&lt;p&gt;Una matrice a gradini è tale per cui, per ogni riga, il primo elemento
non-nullo si trova a destra del primo elemento non-nullo della riga
precedente. Supponiamo ora che $\prod_{i=1}^ma_{ii}\neq 0$. L&amp;rsquo;esempio
mostra che, se $m=n$ e il nostro algoritmo ci fornisce la matrice orlata
a gradini, allora il sistema è risolubile: l&amp;rsquo;ultima riga fornisce
l&amp;rsquo;equazione per $x_n$, la penultima per $x_{n-1}$ e così via: in questo
caso la soluzione del sistema è &lt;em&gt;unica&lt;/em&gt;. Se invece $m&amp;lt;n$, l&amp;rsquo;ultima
equazione è semplicemente&lt;/p&gt;
&lt;p&gt;$$a_{mm}x_m+\dots+a_{mn}x_n=b_m$$ ovvero ci dice che la variabile $x_m$
può essere espressa in termini delle variabili $x_{m+1},\dots,x_{n}$
come $x_m=\frac{1}{a_{mm}}\left(b_m-\sum_{i=m+1}^na_{mi}x_i\right)$. Non
abbiamo sufficiente informazione per fissare le variabili $x_i$ con
$m+1\leq i\leq n$ che peranto rimangono &lt;em&gt;parametri arbitrari&lt;/em&gt; fissati i
quali tutte le altre variabili possono essere fissate univocamente.
Questo vuol dire che le soluzioni del nostro sistema vivono in uno
spazio $n-m$ dimensionale.&lt;/p&gt;
&lt;p&gt;Tuttavia il metodo &lt;em&gt;può fallire&lt;/em&gt; se la matrice a gradini ottenuta ha
$\prod_{i=1}^ma_{ii}=0$ o se $m&amp;gt;n$.&lt;/p&gt;
&lt;p&gt;Cerchiamo di risolvere il sistema&lt;/p&gt;
&lt;p&gt;$$\begin{cases}
2x_1+4x_2-2x_3=2\
4x_1+8x_2-3x_3=8\
-2x_1-4x_2+7x_3=10
\end{cases}&lt;/p&gt;
&lt;p&gt;\Leftrightarrow&lt;/p&gt;
&lt;p&gt;\begin{pmatrix}
2&amp;amp;4&amp;amp;-2\
4&amp;amp;8&amp;amp;-3\
-2&amp;amp;-4&amp;amp;7
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;\begin{pmatrix}
x_1\x_2\x_3
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;=
\begin{pmatrix}2\8\10
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;così che la matrice orlata è&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
2&amp;amp;4&amp;amp;-2&amp;amp;2\
4&amp;amp;8&amp;amp;-3&amp;amp;8\
-2&amp;amp;-4&amp;amp;7&amp;amp;10
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Seguiamo la procedura di Gauss. Al primo step otteniamo&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
2&amp;amp;4&amp;amp;-2&amp;amp;2\
0&amp;amp;0&amp;amp;1&amp;amp;4\
0&amp;amp;0&amp;amp;5&amp;amp;12
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;mentre al secondo&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
2&amp;amp;4&amp;amp;-2&amp;amp;2\
0&amp;amp;0&amp;amp;1&amp;amp;4\
0&amp;amp;0&amp;amp;0&amp;amp;-8
\end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;L&amp;rsquo;ultima riga in particolare corrisponde ad una equazione &lt;em&gt;falsa&lt;/em&gt;,
ovvero $0=-8$. Questo significa che il sistema è &lt;em&gt;incompatibile&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Se $m&amp;gt;n$ la matrice orlata a gradini finale avrà una forma tipo&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
a_{11}&amp;amp;a_{12}&amp;amp;\dots&amp;amp;a_{1m}&amp;amp;\dots&amp;amp;a_{1n}&amp;amp;b_1\
0&amp;amp;a_{22}&amp;amp;\dots&amp;amp;a_{2m}&amp;amp;\dots&amp;amp;a_{2n}&amp;amp;b_2\
\vdots&amp;amp;\vdots&amp;amp;\ddots&amp;amp;\cdots&amp;amp;\cdots&amp;amp;\vdots&amp;amp;\vdots\
0&amp;amp;0&amp;amp;\dots&amp;amp;0&amp;amp;\dots&amp;amp;a_{n,n}&amp;amp;b_{n}\
0&amp;amp;0&amp;amp;\dots&amp;amp;0&amp;amp;\dots&amp;amp;0&amp;amp;b_{n+1}\
0&amp;amp;0&amp;amp;\dots&amp;amp;0&amp;amp;\dots&amp;amp;0&amp;amp;\vdots\
0&amp;amp;0&amp;amp;\dots&amp;amp;0&amp;amp;\dots&amp;amp;0&amp;amp;b_{m}\
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;.$$&lt;/p&gt;
&lt;p&gt;Se, per via della procedura, $b_{n+1}=\dots=b_m=0$, allora possiamo
trascurare tutte le righe dalla $(n+1)$esima in poi, dato che non sono
informative, e ci riduciamo ad un caso in cui di fatto $m=n$.
Diversamente, se uno dei valori $b_i\neq0$ per $n+1\leq i\leq m$, allora
la procedura è risultata in una condizione falsa, che vuol dire che il
nostro sistema è incompatibile e non esistono soluzioni.&lt;/p&gt;
&lt;p&gt;In conclusione, per $m\leq n$, &lt;em&gt;il sistema è compatibile se la matrice
orlata può essere messa in una forma a gradini con
$\prod_{i=1}^ma_{ii}\neq 0$.&lt;/em&gt; Se $n=m$ questa condizione è sufficiente a
garantire che la soluzione è unica. In tutti gli altri casi, il sistema
è incompatibile se la procedura genera equazioni nella forma $0=b_i$ con
$b_i\neq 0$.&lt;/p&gt;
&lt;h3 id=&#34;metodo-di-gauss--jordan-per-linversa&#34;&gt;Metodo di Gauss&amp;ndash;Jordan per l&amp;rsquo;inversa&lt;/h3&gt;
&lt;p&gt;Intuitivamente, il metodo di Gauss descritto sopra, quando ha successo,
permette di &amp;ldquo;invertire&amp;rdquo; la matrice ${\boldsymbol A}$ nell&amp;rsquo;equazione
${\boldsymbol A}{\boldsymbol x}={\boldsymbol b}$ e, in particolare, ci
aspettiamo che, se ${\boldsymbol A}$ è una matrice quadrata invertibile,
allora in effetti ${\boldsymbol x}={\boldsymbol A}^{-1}{\boldsymbol b}$.
In qualche modo, in questo caso, il metodo produce esattamente il
risultato di questa operazione applicando l&amp;rsquo;inversa di ${\boldsymbol A}$
a ${\boldsymbol b}$, quando questa esiste.&lt;/p&gt;
&lt;p&gt;In effetti, supponiamo che la matrice
${\boldsymbol A}\in\mathcal M_{n,n}({\mathbb K})$. La matrice inversa
${\boldsymbol A}^{-1}$ è tale per cui
${\boldsymbol A}{\boldsymbol A}^{-1}={\boldsymbol I}_n$. Se denoto con
${\boldsymbol x}_i$ la $i$-esima colonna di ${\boldsymbol A}^{-1}$&lt;/p&gt;
&lt;p&gt;$${\boldsymbol A}{\boldsymbol x}_i={\boldsymbol e}&lt;em&gt;i,\qquad \text{dove}\quad {\boldsymbol e}&lt;em&gt;i=(\delta&lt;/em&gt;{\nu i})&lt;/em&gt;{\nu}\quad \text{per }i=1,\dots, n.$$&lt;/p&gt;
&lt;p&gt;In sostanza trovare l&amp;rsquo;inversa equivale a risolvere contemporaneamente
$n$ sistemi di equazioni lineari, problema per il quale possiamo
applicare il metodo di Gauss. Per meglio esemplificare questo fatto,
ricorriamo ad un esempio.&lt;/p&gt;
&lt;p&gt;Consideriamo la matrice quadrata&lt;/p&gt;
&lt;p&gt;$${\boldsymbol A}=
\begin{pmatrix}
2&amp;amp;-1&amp;amp;0\
-1&amp;amp;2&amp;amp;-1\
0&amp;amp;-1&amp;amp;2\
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;.$$ Per trovare l&amp;rsquo;inversa&lt;/p&gt;
&lt;p&gt;$${\boldsymbol A}^{-1}=
\begin{pmatrix}
x_{11}&amp;amp;x_{12}&amp;amp;x_{13}\
x_{21}&amp;amp;x_{22}&amp;amp;x_{23}\
x_{31}&amp;amp;x_{22}&amp;amp;x_{33}\
\end{pmatrix}
$$ occorre risolvere le equazioni&lt;/p&gt;
&lt;p&gt;$$\medmuskip=0mu
\thinmuskip=0mu
\thickmuskip=0mu
\begin{pmatrix}
2&amp;amp;-1&amp;amp;0\
-1&amp;amp;2&amp;amp;-1\
0&amp;amp;-1&amp;amp;2\
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;\begin{pmatrix}
x_{11}\x_{21}\x_{31}
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;=
\begin{pmatrix}
1\0\0
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;,\qquad
\begin{pmatrix}
2&amp;amp;-1&amp;amp;0\
-1&amp;amp;2&amp;amp;-1\
0&amp;amp;-1&amp;amp;2\
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;\begin{pmatrix}
x_{11}\x_{21}\x_{31}
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;=
\begin{pmatrix}
0\1\0
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;,\qquad
\begin{pmatrix}
2&amp;amp;-1&amp;amp;0\
-1&amp;amp;2&amp;amp;-1\
0&amp;amp;-1&amp;amp;2\
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;\begin{pmatrix}
x_{11}\x_{21}\x_{31}
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;=
\begin{pmatrix}
0\0\1
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;.$$ Possiamo immaginare di procedere parallelamente su tutti i sistemi
usando una matrice orlata&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
2&amp;amp;-1&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\
-1&amp;amp;2&amp;amp;-1&amp;amp;0&amp;amp;1&amp;amp;0\
0&amp;amp;-1&amp;amp;2&amp;amp;0&amp;amp;0&amp;amp;1\
\end{pmatrix}
$$ Questa matrice orlata ha la forma&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
{\boldsymbol A}&amp;amp;{\boldsymbol I}
\end{pmatrix}
$$ Usando la procedura di Gauss per mettere la matrice in
forma a gradini si ottiene&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
2&amp;amp;-1&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\
0&amp;amp;\sfrac{3}{2}&amp;amp;-1&amp;amp;\sfrac{1}{2}&amp;amp;1&amp;amp;0\
0&amp;amp;0&amp;amp;\sfrac{4}{3}&amp;amp;\sfrac{2}{3}&amp;amp;\sfrac{2}{3}&amp;amp;1\
\end{pmatrix}
$$ A questo punto vorremmo mettere il sistema nella forma&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
{\boldsymbol I}&amp;amp;{\boldsymbol B}
\end{pmatrix}
$$ perché in questo caso
${\boldsymbol B}={\boldsymbol A}^{-1}$! La matrice orlata ottenuta
infatti corrisponderebbe al set di sistemi $x_{\mu\nu}=b_{\mu\nu}$
fornendoci la soluzione che cerchiamo. Dobbiamo quindi lavorare per
rimuovere gli zeri &lt;em&gt;sopra&lt;/em&gt; la diagonale procedendo stavolta dal basso
verso l&amp;rsquo;alto.&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
2&amp;amp;-1&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\
0&amp;amp;\sfrac{3}{2}&amp;amp;-1&amp;amp;\sfrac{3}{4}&amp;amp;\sfrac{3}{2}&amp;amp;\sfrac{3}{4}\
0&amp;amp;0&amp;amp;\sfrac{4}{3}&amp;amp;\sfrac{2}{3}&amp;amp;\sfrac{2}{3}&amp;amp;1
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;\Rightarrow
\begin{pmatrix}
2&amp;amp;-1&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\
0&amp;amp;\sfrac{3}{2}&amp;amp;0&amp;amp;\sfrac{3}{4}&amp;amp;\sfrac{3}{2}&amp;amp;\sfrac{3}{4}\
0&amp;amp;0&amp;amp;\sfrac{4}{3}&amp;amp;\sfrac{2}{3}&amp;amp;\sfrac{2}{3}&amp;amp;1
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;\Rightarrow
\begin{pmatrix}
2&amp;amp;0&amp;amp;0&amp;amp;\sfrac{3}{2}&amp;amp;1&amp;amp;\sfrac{1}{2}\
0&amp;amp;\sfrac{3}{2}&amp;amp;0&amp;amp;\sfrac{3}{4}&amp;amp;\sfrac{3}{2}&amp;amp;\sfrac{3}{4}\
0&amp;amp;0&amp;amp;\sfrac{4}{3}&amp;amp;\sfrac{1}{3}&amp;amp;\sfrac{2}{3}&amp;amp;1
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;.$$ Dividendo opportunamente ogni riga otteniamo&lt;/p&gt;
&lt;p&gt;$$\begin{pmatrix}
1&amp;amp;0&amp;amp;0&amp;amp;\sfrac{3}{4}&amp;amp;\sfrac{1}{2}&amp;amp;\sfrac{1}{4}\
0&amp;amp;1&amp;amp;0&amp;amp;\sfrac{1}{2}&amp;amp;1&amp;amp;\sfrac{1}{2}\
0&amp;amp;0&amp;amp;1&amp;amp;\sfrac{1}{4}&amp;amp;\sfrac{1}{2}&amp;amp;\sfrac{3}{4}
\end{pmatrix}
$$ per cui&lt;/p&gt;
&lt;p&gt;$${\boldsymbol A}^{-1}=
\begin{pmatrix}
\sfrac{3}{4}&amp;amp;\sfrac{1}{2}&amp;amp;\sfrac{1}{4}\
\sfrac{1}{2}&amp;amp;1&amp;amp;\sfrac{1}{2}\
\sfrac{1}{4}&amp;amp;\sfrac{1}{2}&amp;amp;\sfrac{3}{4}
\end{pmatrix}&lt;/p&gt;
&lt;p&gt;.$$&lt;/p&gt;
&lt;p&gt;Il metodo descritto è detto &lt;em&gt;di Gauss&amp;ndash;Jordan&lt;/em&gt;. La procedura fallisce se
l&amp;rsquo;inversa cercata non esiste. Questo è il caso, per esempio, se &lt;em&gt;dopo&lt;/em&gt;
aver ottenuto la forma a gradini $\prod_{i=1}^na_{ii}=0$. Questa
condizione ha un significato preciso che specificheremo.&lt;/p&gt;
&lt;h3 id=&#34;rango&#34;&gt;Rango&lt;/h3&gt;
&lt;p&gt;Il metodo di eliminazione di Gauss permette di risolvere un sistema di
equazioni lineari, o determinarne l&amp;rsquo;incompatibilità. Non fornisce però
(almeno direttamente) un &lt;em&gt;criterio&lt;/em&gt; di risolubilità né è chiaro perché
in alcuni casi dovrebbe funzionare e in altri fallire. A questo scopo
introduciamo il concetto di &lt;em&gt;rango&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Dato un insieme finito di vettori ${{\boldsymbol v}&lt;em&gt;i}&lt;/em&gt;{i=1}^k$ di uno
spazio vettoriale $\mathbb V$, il rango dell&amp;rsquo;insieme è la dimensione di
$\mathrm{span}[{{\boldsymbol v}&lt;em&gt;i}&lt;/em&gt;{i=1}^k]$.&lt;/p&gt;
&lt;p&gt;Data una matrice ${\boldsymbol A}$ possiamo quindi assegnarle, in linea
di principio, un rango per righe, ovvero il numero massimo di sue righe
linearmenti indipendenti, e un rango per colonne, ovvero il numero
massimo di sue colonne linearmenti indipendenti. Tuttavia, vale il
seguente&lt;/p&gt;
&lt;p&gt;Il rango per righe e il rango per colonne di una matrice
${\boldsymbol A}\in{\mathbb R}^{m\times n}$ coincidono.&lt;/p&gt;
&lt;p&gt;Denotiamo d&amp;rsquo;ora in poi $r({\boldsymbol A})$ il rango di
${\boldsymbol A}$: naturalmente $r({\boldsymbol A})\leq \min{n,m}$. Il
rango di una matrice ha numerose proprietà, che non elencheremo,
eccezion fatta per la seguente&lt;/p&gt;
&lt;p&gt;Una matrice quadrata ${\boldsymbol A}\in\mathcal M_{n,n}({\mathbb K})$ è
invertibile se e solo se il suo rango è $n$.&lt;/p&gt;
&lt;p&gt;Di conseguenza, il rango di una matrice è massimo se e solo se il suo
determinante è non nullo.&lt;/p&gt;
&lt;p&gt;Il rango di una matrice rimane inalterato eseguendo le opreazioni
lineari del metodo di Gauss, ed è uguale al numero di righe non-nulle
ottenute alla fine dell&amp;rsquo;esecuazione all&amp;rsquo;interno della matrice
${\boldsymbol A}$ trasformata. Il fatto che il rango di una matrice sia
legato alla risolubilità di un sistema lineare è suggerito dal seguente
fatto. Consideriamo il problema
${\boldsymbol A}{\boldsymbol x}={\boldsymbol b}$: se indichiamo con
${\boldsymbol a}^\nu$ la $\mu$-esima colonna di ${\boldsymbol A}$,
questo problema può scriversi come&lt;/p&gt;
&lt;p&gt;$$\sum_{\nu=1}^n x_\nu{\boldsymbol a}^\nu={\boldsymbol b},$$&lt;/p&gt;
&lt;p&gt;che esprime il fatto che stiamo cercando di scrivere ${\boldsymbol b}$
come sovrapposizione lineare dei vettori colonna di ${\boldsymbol A}$,
${{\boldsymbol a}^\nu}&lt;em&gt;{\nu=1}^n$. Ciò sarà possibile se
${\boldsymbol b}$ vive nello spazio generato dalle colonne di
${\boldsymbol A}$, $\mathrm{span}[{{\boldsymbol a}^\nu}&lt;/em&gt;{\nu=1}^n]$,
la cui dimensione è $r({\boldsymbol A})$. Questa intuizione è espressa
in termini rigorosi da un teorema fondamentale dell&amp;rsquo;algebra lineare, che
diamo senza dimostrazione.&lt;/p&gt;
&lt;p&gt;Un sistema lineare di $m$ equazioni in $n$ incognite
${\boldsymbol A}{\boldsymbol x}={\boldsymbol b}$ è compatibile se e solo
se la matrice orlata ha lo stesso rango della matrice ${\boldsymbol A}$.
In tal caso, lo spazio delle soluzioni ha dimensione
$n-r({\boldsymbol A})$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sistemi di equazioni lineari</title>
      <link>https://gsicuro.github.io/lectures/im2/ch1/sec3/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/lectures/im2/ch1/sec3/</guid>
      <description>&lt;p&gt;Content&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Operatori lineari e spettri</title>
      <link>https://gsicuro.github.io/lectures/im2/ch1/sec4/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/lectures/im2/ch1/sec4/</guid>
      <description>&lt;p&gt;Content&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://gsicuro.github.io/publications/</link>
      <pubDate>Thu, 14 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/publications/</guid>
      <description>&lt;iframe type=&#34;text/html&#34; sandbox=&#34;allow-scripts allow-same-origin allow-popups&#34; width=&#34;336&#34; height=&#34;550&#34; frameborder=&#34;0&#34; allowfullscreen style=&#34;max-width:45&#34; src=&#34;https://read.amazon.com/kp/card?asin=B01M4NFA51&amp;preview=inline&amp;linkCode=kpe&amp;ref_=cm_sw_r_kb_dp_NT1Y2ZQ2WYTV618DW936&#34; &gt;&lt;/iframe&gt;
&lt;iframe type=&#34;text/html&#34; sandbox=&#34;allow-scripts allow-same-origin allow-popups&#34; width=&#34;336&#34; height=&#34;550&#34; frameborder=&#34;0&#34; allowfullscreen style=&#34;max-width:45%&#34; src=&#34;https://read.amazon.com/kp/card?asin=B0CFLFFSNH&amp;preview=inline&amp;linkCode=kpe&amp;ref_=cm_sw_r_kb_dp_2M07EK3QZZGHYBF6J6DK&#34; &gt;&lt;/iframe&gt;
&lt;hr&gt;
&lt;html&gt;
&lt;head&gt;
&lt;script type=&#34;text/javascript&#34;&gt;
var arxiv_authorid = &#34;0000-0002-9258-2436&#34;;
var arxiv_format=&#34;arxiv&#34;;
var arxiv_includeSubjects=0;
var arxiv_max_entries=0;
&lt;/script&gt;
&lt;style type=&#34;text/css&#34;&gt;
div.arxivfeed {margin-bottom: 5px; width:90%;}
&lt;/style&gt;
&lt;script type=&#34;text/javascript&#34; src=&#34;https://arxiv.org/js/myarticles.js&#34;&gt;
&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;div id=&#34;arxivfeed&#34;&gt;&lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    
    <item>
      <title>Disordered Systems Days at King&#39;s College London</title>
      <link>https://gsicuro.github.io/news/kuhn2023/</link>
      <pubDate>Tue, 12 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/news/kuhn2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spin Glass Theory &amp; Far Beyond</title>
      <link>https://gsicuro.github.io/news/rsb40/</link>
      <pubDate>Fri, 30 Jun 2023 10:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/news/rsb40/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Facets of Statistical Field Theory</title>
      <link>https://gsicuro.github.io/news/caracciolo2022/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/news/caracciolo2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MECO47</title>
      <link>https://gsicuro.github.io/news/meco47/</link>
      <pubDate>Sun, 12 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/news/meco47/</guid>
      <description></description>
    </item>
    
    <item>
      <title>73rd British Mathematical Colloquium</title>
      <link>https://gsicuro.github.io/news/bmc2022/</link>
      <pubDate>Mon, 06 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/news/bmc2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Past students</title>
      <link>https://gsicuro.github.io/alumni/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/alumni/</guid>
      <description>&lt;h2 id=&#34;phd-students&#34;&gt;PhD students&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;2025, &lt;strong&gt;Urte Adomaityte&lt;/strong&gt;. King&amp;rsquo;s College London.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;master-students&#34;&gt;Master students&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;2016, &lt;strong&gt;Matteo P. D&amp;rsquo;Achille&lt;/strong&gt;. Thesis: &lt;a href=&#34;https://gsicuro.github.io/uploads/dachille.pdf&#34;&gt;&lt;em&gt;On two assignment problems&lt;/em&gt;&lt;/a&gt;, co-supervised with Sergio Caracciolo, University of Milan.&lt;/li&gt;
&lt;li&gt;2018, &lt;strong&gt;Gianmarco Perrupato&lt;/strong&gt;. Thesis: &lt;a href=&#34;https://gsicuro.github.io/uploads/perrupato.pdf&#34;&gt;&lt;em&gt;Study of matching on the Bethe lattice&lt;/em&gt;&lt;/a&gt;, co-supervised with Giorgio Parisi, Sapienza University of Rome.&lt;/li&gt;
&lt;li&gt;2021, &lt;strong&gt;Anshul Toshniwal&lt;/strong&gt;. Thesis: &lt;em&gt;The planted multi-index matching problem&lt;/em&gt;, co-supervised with Lenka Zdeborová, EPFL.&lt;/li&gt;
&lt;li&gt;2021, &lt;strong&gt;Claudia De Sousa Miranda Perez&lt;/strong&gt;. Thesis: &lt;a href=&#34;https://gsicuro.github.io/uploads/desousa.pdf&#34;&gt;&lt;em&gt;The random dimer covering problem on the weighted Aztec graph&lt;/em&gt;&lt;/a&gt;, King&amp;rsquo;s College London.&lt;/li&gt;
&lt;li&gt;2021, &lt;strong&gt;Daniel Reti&lt;/strong&gt;. Thesis: &lt;a href=&#34;https://gsicuro.github.io/uploads/reti.pdf&#34;&gt;&lt;em&gt;Robustness of excitations in the random dimer model&lt;/em&gt;&lt;/a&gt;, King&amp;rsquo;s College London.&lt;/li&gt;
&lt;li&gt;2021, &lt;strong&gt;Hugo Ryder&lt;/strong&gt;. Thesis: &lt;a href=&#34;https://gsicuro.github.io/uploads/ryder.pdf&#34;&gt;&lt;em&gt;Matching recovery&lt;/em&gt;&lt;/a&gt;, King&amp;rsquo;s College London.&lt;/li&gt;
&lt;li&gt;2021, &lt;strong&gt;Leonardo Scialo&lt;/strong&gt;. Thesis: &lt;a href=&#34;https://gsicuro.github.io/uploads/scialo.pdf&#34;&gt;&lt;em&gt;Arctic region in the weighted random dimer covering&lt;/em&gt;&lt;/a&gt;, King&amp;rsquo;s College London.&lt;/li&gt;
&lt;li&gt;2022, &lt;strong&gt;Guoyu Chang&lt;/strong&gt;. Thesis: &lt;em&gt;The mixed multi-index matching problem&lt;/em&gt;, King&amp;rsquo;s College London.&lt;/li&gt;
&lt;li&gt;2022, &lt;strong&gt;Xiaoying Zhou&lt;/strong&gt;. Thesis: &lt;em&gt;Statistical physics of community detection&lt;/em&gt;, King&amp;rsquo;s College London.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>MSc Complex System Modelling</title>
      <link>https://gsicuro.github.io/education/master/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/education/master/</guid>
      <description>&lt;div class=&#34;row&#34;&gt;
  &lt;div class=&#34;col-sm-5&#34;&gt;
      &lt;div class=&#34;card-body&#34;&gt;
        &lt;h6 class=&#34;card-title&#34;&gt;Programme Director&lt;/h6&gt;
        &lt;a href=&#34;mailto:benjamin.doyon@kcl.ac.uk&#34; class=&#34;card-text&#34;&gt; Prof. Benjamin Doyon&lt;/a&gt;
      &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&#34;col-sm-7&#34;&gt;
      &lt;div class=&#34;card-body&#34;&gt;
        &lt;h6 class=&#34;card-title&#34;&gt;Assessment Sub Board Chair&lt;/h6&gt;
        &lt;a href=&#34;mailto:yan.fyodorov@kcl.ac.uk&#34; class=&#34;card-text&#34;&gt; Prof. Yan Fyodorov&lt;/a&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;strong&gt;MSc Complex System Modelling&lt;/strong&gt; is run by the Disordered Systems group, one of the research groups in the Department of Mathematics at KCL, in collaboration with the &lt;a href=&#34;https://www.kcl.ac.uk/research/financial-maths&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Financial Mathematics group&lt;/a&gt; and the Departments of &lt;a href=&#34;https://www.kcl.ac.uk/informatics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Informatics&lt;/a&gt; and &lt;a href=&#34;https://www.kcl.ac.uk/physics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Physics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/fS5sHGW5PEw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

 &lt;/p&gt;
&lt;p&gt;Read &lt;a href=&#34;https://blogs.kcl.ac.uk/nms/2020/01/27/why-i-chose-complex-systems-modelling/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; the experience of a student that studied with us.&lt;/p&gt;
&lt;p&gt;Prospective students may also find useful our brochure and student testimonial. To apply for the programme click here.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kcl.ac.uk/study/postgraduate/taught-courses/complex-systems-modelling-msc&#34; class=&#34;btn btn-primary btn-lg btn-block active&#34; role=&#34;button&#34; aria-pressed=&#34;true&#34;&gt;&lt;strong&gt;Apply&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-danger&#34;&gt;
  &lt;i class=&#34;fas fa-exclamation-triangle&#34;&gt;&lt;/i&gt; &lt;strong&gt;Note:&lt;/strong&gt; Due to Covid19, students will be given the opportunity to take this programme entirely remotely in 2020/21, if they wish to do so. All the course material will be made available online and there will be regular live interactions with lecturers and tutors.
&lt;/div&gt;
&lt;h2 id=&#34;course-pre-requisites&#34;&gt;Course pre-requisites&lt;/h2&gt;
&lt;p&gt;The course has as entry requirement first or upper second class in &lt;strong&gt;Mathematics&lt;/strong&gt; or &lt;strong&gt;Physics&lt;/strong&gt;. Outstanding candidates from other degrees in quantitative subjects may be considered, provided they have had sufficient exposure to mathematical and physical sciences. Please check whether your background is suitable for this programme, by answering our &lt;a href=&#34;http://www.nms.kcl.ac.uk/CSMMSC/CSM_Questionnaire-2021.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;admission questionnaire&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have a few gaps in your background or need a refresher, we offer a non-examinable support course, &lt;a href=&#34;https://keats.kcl.ac.uk/course/view.php?id=66816&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Foundations for CSM&lt;/a&gt;, which runs for 6 weeks in Semester I. You are encouraged to start reading the &lt;a href=&#34;http://www.nms.kcl.ac.uk/CSMMSC/Course_Book.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lecture notes&lt;/a&gt; prior to the start of the course.&lt;/p&gt;
&lt;h1 id=&#34;general-information&#34;&gt;General Information&lt;/h1&gt;
&lt;h2 id=&#34;course-structure&#34;&gt;Course Structure&lt;/h2&gt;
&lt;p&gt;The course is &lt;strong&gt;one year&lt;/strong&gt; long if attended full-time, or two years long if attended Part-time, from September to September. It consists of &lt;strong&gt;8 modules&lt;/strong&gt; (15 credits each) plus a &lt;em&gt;Summer research project&lt;/em&gt; (60 credits, running from June to September) for a total of 180 credits.
You can also take up to two modules from other &lt;strong&gt;University of London institutions&lt;/strong&gt;, such as UCL and QMUL, subject to the approval of the programme director. See the &lt;a href=&#34;http://www.nms.kcl.ac.uk/CSMMSC/1920induction.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Induction slides&lt;/a&gt; and the &lt;a href=&#34;http://www.nms.kcl.ac.uk/CSMMSC/Modules1920.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Induction handouts&lt;/a&gt; for more information.&lt;/p&gt;
&lt;div class=&#34;card text-center&#34;&gt;
  &lt;div class=&#34;card-header&#34;&gt;
  &lt;/div&gt;
  &lt;div class=&#34;card-body&#34;&gt;
    &lt;p class=&#34;card-text&#34;&gt;Take a look to the detailed structure of the module on KEATS.&lt;/p&gt;
    &lt;a href=&#34;https://keats.kcl.ac.uk/mod/book/view.php?id=3259805&amp;chapterid=276617&#34; class=&#34;btn btn-primary&#34;&gt;Go to KEATS!&lt;/a&gt;
  &lt;/div&gt;
  &lt;div class=&#34;card-footer text-muted&#34;&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;expected-workload&#34;&gt;Expected workload&lt;/h2&gt;
&lt;p&gt;The workload is at least &lt;strong&gt;10 hours per module per week&lt;/strong&gt;, typically distributed as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3 hours lecture (some modules may have 2 hours);&lt;/li&gt;
&lt;li&gt;1 hour tutorial;&lt;/li&gt;
&lt;li&gt;6 hours self-study and coursework (depending on your background, some modules may require more hours).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;assessment&#34;&gt;Assessment&lt;/h2&gt;
&lt;p&gt;Assessments are mostly two-hour written exams in May (very few modules have January exams). They consits in essays, oral presentations and dissertations. Practicals, class tests and assessed courseworks are possible, depending on the modules selected. Resits opportunities (for modules failed in May) are normally offered in August&lt;/p&gt;
&lt;h1 id=&#34;additional-information-and-documents&#34;&gt;Additional information and documents&lt;/h1&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting started&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;For an &lt;strong&gt;overview&lt;/strong&gt; of the programme see the &lt;a href=&#34;http://www.nms.kcl.ac.uk/CSMMSC/1920induction.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Induction slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For detailed &lt;strong&gt;module information&lt;/strong&gt; see the &lt;a href=&#34;http://www.nms.kcl.ac.uk/CSMMSC/Modules1920.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Induction handouts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;All the information about &lt;strong&gt;Summer projects&lt;/strong&gt; can be found on the &lt;a href=&#34;https://keats.kcl.ac.uk/course/view.php?id=66817&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KEATS page&lt;/a&gt;. This will include the most recent version of the &lt;a href=&#34;http://www.nms.kcl.ac.uk/CSMMSC/CSM_and_CANES_Dissertation_Handbook-18-19.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;dissertation handbook&lt;/a&gt; and a list of projects that were &lt;a href=&#34;http://www.nms.kcl.ac.uk/CSMMSC/Projects-1920.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;offered in previous years&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;online-handbooks-and-timetables&#34;&gt;Online handbooks and timetables&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Online handbook for the &lt;a href=&#34;https://www.kcl.ac.uk/study/postgraduate/taught-courses/complex-systems-modelling-msc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MSc CSM programme&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Online handbook for the &lt;a href=&#34;https://keats.kcl.ac.uk/course/view.php?id=68787&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mathematics Department&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kcl.ac.uk/aboutkings/Academic-Calendar&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Term dates&lt;/a&gt; and &lt;a href=&#34;https://timetables.kcl.ac.uk/KCLSWS/SDB1920RDB/login.aspx?ReturnUrl=%2fkclsws%2fSDB1920RDB%2fdefault.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KCL timetable&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;documents&#34;&gt;Documents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Module Amendment Form&lt;/li&gt;
&lt;li&gt;Mitigating circumstances form&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;career-prospects&#34;&gt;Career prospects&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A non-exhaustive &lt;a href=&#34;http://www.nms.kcl.ac.uk/CSMMSC/Career_prospect.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;list of potential employers&lt;/a&gt; in Complex Systems&lt;/li&gt;
&lt;li&gt;Adverts of career and networking events for MSc students in Mathematics are regularly circulated by &lt;a href=&#34;mailto:pg-mathematics@kcl.ac.uk&#34;&gt;pg-mathematics@kcl.ac.uk&lt;/a&gt; through the CSM mailing list&lt;/li&gt;
&lt;li&gt;Some of the events organised by &lt;a href=&#34;https://www.kcl.ac.uk/careers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KCL Careers&lt;/a&gt; may also be of interest&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Apply to the KCL MPhil/PhD Mathematics Program</title>
      <link>https://gsicuro.github.io/education/mphilphd/</link>
      <pubDate>Thu, 25 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/education/mphilphd/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/f0N1muuhIV0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

 &lt;/p&gt;
&lt;div class=&#34;row&#34;&gt;
  &lt;div class=&#34;col-sm-7&#34;&gt;
      &lt;div class=&#34;card-body&#34;&gt;
        &lt;h6 class=&#34;card-title&#34;&gt;PGR Admission Tutor&lt;/h6&gt;
        &lt;a href=&#34;mailto:pierpaolo.vivo@kcl.ac.uk&#34; class=&#34;card-text&#34;&gt; Dr. Pierpaolo Vivo&lt;/a&gt;
      &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&#34;col-sm-5&#34;&gt;
      &lt;div class=&#34;card-body&#34;&gt;
        &lt;h6 class=&#34;card-title&#34;&gt;Contacts&lt;/h6&gt;
        &lt;a href=&#34;mailto:pgr-mathematics@kcl.ac.uk&#34; class=&#34;card-text&#34;&gt; &lt;i class=&#34;fas fa-envelope&#34;&gt;&lt;/i&gt; PGR Office&lt;/a&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The Disordered Systems group is constantly engaged in the supervision of PhD candidates in Mathematics and Applied Mathematics within our Department. All applications are processed through the King&amp;rsquo;s appplication system, accessible from the link below.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kcl.ac.uk/study-legacy/postgraduate/research-courses/applied-mathematics-research-mphil-phd&#34; class=&#34;btn btn-primary btn-lg btn-block active&#34; role=&#34;button&#34; aria-pressed=&#34;true&#34;&gt;&lt;strong&gt;King&amp;rsquo;s application system&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;phd-projects&#34;&gt;PhD projects&lt;/h2&gt;
&lt;div class=&#34;alert alert-info&#34; id=&#34;#ivan&#34;&gt;
&lt;a name=&#34;ivan&#34;&gt;&lt;/a&gt;
  &lt;i class=&#34;fa-solid fa-diagram-project&#34;&gt;&lt;/i&gt;
  &lt;h2 style=&#34;font-size:10;font-family:roboto&#34;&gt; The mathematics of adaptive, stable and robust Artificial Intelligence&lt;/h2&gt;
 &lt;div style=&#34;text-align: justify&#34;&gt;
 &lt;strong&gt; Supervisor: &lt;/strong&gt;
 &lt;a href=&#34;mailto:ivan.tyukin@kcl.ac.uk&#34; class=&#34;card-text&#34;&gt; &lt;i class=&#34;fas fa-envelope&#34;&gt;&lt;/i&gt; Prof Ivan Tyukin&lt;/a&gt;
&lt;p&gt;&lt;strong&gt; Status: &lt;/strong&gt; Open.&lt;/p&gt;
&lt;p&gt;The studentship covers tuition fees for &lt;a href=&#34;https://www.ukcisa.org.uk/Information--Advice/Fees-and-Money/England-HE-fee-status#layer-6082&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Home/UK students&lt;/strong&gt;&lt;/a&gt; and a stipend of £19,668 per annum. The funding is available for 3.5 years. Overseas applicants will be considered but they must demonstrate the capability to fund the difference between International full-time fees (currently £28,260 per annum for 2023/2024 academic year) and Home/UK fees.&lt;/p&gt;
&lt;hr class=&#34;rounded&#34;&gt;
&lt;strong&gt; Description &amp;mdash; &lt;/strong&gt; Recent years have seen explosive growth in the applications of Artificial Intelligence (AI). Notwithstanding significant successes of the new technology, empirical evidence points to numerous examples of errors in the decisions of state-of-the-art AI systems. Current theoretical works confirm that modern design practices and classical mathematical frameworks supporting these could suffer from various fundamental shortcomings including the typicality of adversarial attacks, susceptibility to backdoors and stealth attacks, instabilities, and hallucinations. At the same time, there is a plethora of under-explored and seemingly controversial phenomena, such as learning from scarce yet high-dimensional information, which has been broadly observed experimentally in large-scale AI systems but whose complete mathematical understanding is yet to be developed. Other factors hindering the performance of current AI systems include the need to adapt to concept drifts and unforeseen changes in operational conditions.
&lt;p&gt;The project aims to explore and systematically assess major causes of AI errors and instabilities and develop appropriate mathematical foundations enabling the creation of stable and robust Artificial Intelligence capable of dealing with errors and concept drifts. The successful candidate will work alongside a team of early career researchers funded by the UKRI Turing AI Acceleration Fellowship (EP/V025295/2) and will benefit from the team’s established relationships with industrial partners, academic networks (Turing AI Fellows, Trustworthy Autonomous Systems Node in Verifiability EP/V026801/2), and other collaborators in academia, healthcare, defence &amp;amp; security.&lt;/p&gt;
&lt;hr class=&#34;rounded&#34;&gt;
&lt;p&gt;&lt;strong&gt; How to apply — &lt;/strong&gt; To state your interest, please contact directly &lt;a href=&#34;mailto:ivan.tyukin@kcl.ac.uk&#34; class=&#34;card-text&#34;&gt; &lt;i class=&#34;fas fa-envelope&#34;&gt;&lt;/i&gt; &lt;strong&gt;Prof Ivan Tyukin&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-info&#34; id=&#34;#paola&#34;&gt;
&lt;a name=&#34;paola&#34;&gt;&lt;/a&gt;
  &lt;i class=&#34;fa-solid fa-diagram-project&#34;&gt;&lt;/i&gt;
  &lt;h2 style=&#34;font-size:10;font-family:roboto&#34;&gt; 
  Entanglement and universality in inhomogeneous and out-of-equilibrium many body quantum systems &lt;/h2&gt;
 &lt;div style=&#34;text-align: justify&#34;&gt;
 &lt;strong&gt; Supervisors: &lt;/strong&gt;
 &lt;a href=&#34;mailto:paola.ruggiero@kcl.ac.uk&#34; class=&#34;card-text&#34;&gt; &lt;i class=&#34;fas fa-envelope&#34;&gt;&lt;/i&gt; Dr Paola Ruggiero&lt;/a&gt; and 
 &lt;a href=&#34;mailto:benjamin.doyon@kcl.ac.uk&#34; class=&#34;card-text&#34;&gt; &lt;i class=&#34;fas fa-envelope&#34;&gt;&lt;/i&gt; Prof Ben Doyon&lt;/a&gt;
&lt;p&gt;&lt;strong&gt; Status: &lt;/strong&gt; Open.&lt;/p&gt;
&lt;p&gt;We would like to bring to your attention a &lt;a href=&#34;https://www.ukcisa.org.uk/Information--Advice/Fees-and-Money/England-HE-fee-status#layer-6082&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;funded home-student&lt;/strong&gt;&lt;/a&gt; PhD fellowship available in the Disordered System group at King’s College London. This is to be co-supervised by Dr Paola Ruggiero and Prof Benjamin Doyon, and to start in October 2023. The PhD project covers a broad range of topics in statistical physics and quantum many-body systems, and will be adapted to the interests of the candidate. A general description of the project can be found below.&lt;/p&gt;
&lt;hr class=&#34;rounded&#34;&gt;
&lt;strong&gt; Description &amp;mdash; &lt;/strong&gt; The project lies at the intersection of several different fields: from statistical physics to quantum information, from high energy to condensed matter physics. The common denominators are the phenomenon of quantum entanglement and the out-of-equilibrium behaviour of many-body quantum systems, particularly in low dimensional quantum many body systems. While the emergence of universality is rather well established for systems which are homogeneous and are at equilibrium, the same is not true for inhomogeneous systems, both in and out of equilibrium. Those, on the other hand, are the rule rather than the exception in the context of quantum experiments. Different new tools are currently under study to investigate what remains of the aforementioned universality in such more complicated situations, and the projects aims to gain a better understanding of this topic, especially through the “lenses” of entanglement.
&lt;hr class=&#34;rounded&#34;&gt;
&lt;p&gt;&lt;strong&gt; How to apply — &lt;/strong&gt; If you have home-fees student status, in order to express your interest, &lt;strong&gt;please submit first your CV and two reference letters to&lt;/strong&gt; &lt;a href=&#34;mailto:paola.ruggiero@kcl.ac.uk&#34; class=&#34;card-text&#34;&gt; &lt;i class=&#34;fas fa-envelope&#34;&gt;&lt;/i&gt; &lt;strong&gt;Paola Ruggiero&lt;/strong&gt;&lt;/a&gt;. As a next step, apply for an Applied Mathematics Research Degree in the Mathematics Department via the King&amp;rsquo;s application system.
&lt;a href=&#34;https://apply.kcl.ac.uk/&#34; class=&#34;btn btn-info btn-lg btn-block active&#34; role=&#34;button&#34; aria-pressed=&#34;true&#34;&gt;&lt;strong&gt;Direct link to the application page&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>40 years of Replica Symmetry Breaking</title>
      <link>https://gsicuro.github.io/news/confrsb40/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/news/confrsb40/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Disordered serendipity</title>
      <link>https://gsicuro.github.io/news/parisi70/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/news/parisi70/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Beyond mean field theory</title>
      <link>https://gsicuro.github.io/news/bmft/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/news/bmft/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Disordered systems</title>
      <link>https://gsicuro.github.io/project/ds/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/project/ds/</guid>
      <description>&lt;p&gt;The research activities of the group concentrate on the analysis and development of mathematical theories and models with which to describe the statics and dynamics of disordered (or &amp;ldquo;complex&amp;rdquo;) systems in physics, biology, financial markets, and computer science. Such systems are characterized by microscopic (usually stochastic) dynamic elements with mutual interactions without global regularity but with a significant degree of built-in competition and incompatibility, resulting in the existence of many locally stable states for the system as a whole and a highly non-ergodic &amp;ldquo;glassy&amp;rdquo; type of dynamics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://gsicuro.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://gsicuro.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
